{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e3efb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing S01\n",
      "Reading /System/Volumes/Data/misc/data12/sjapee/Sebastian-OrientationImagery/Data/Bids/derivatives/preprocessed/sub-S01_Still_preprocessed-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     600.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Adding metadata with 8 columns\n",
      "1104 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "running cv #0 out of 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process LokyProcess-2:\n",
      "Process LokyProcess-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/montesinossl/anaconda3/envs/mne2/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/montesinossl/anaconda3/envs/mne2/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/montesinossl/anaconda3/envs/mne2/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py\", line 481, in _process_worker\n",
      "    if time() - _last_memory_leak_check > _MEMORY_LEAK_CHECK_DELAY:\n",
      "       ^^^^^^\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/montesinossl/anaconda3/envs/mne2/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/montesinossl/anaconda3/envs/mne2/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/montesinossl/anaconda3/envs/mne2/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py\", line 481, in _process_worker\n",
      "    if time() - _last_memory_leak_check > _MEMORY_LEAK_CHECK_DELAY:\n",
      "       ^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 135\u001b[0m\n\u001b[1;32m    133\u001b[0m model_predictions \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m reg_name, (model_class, model_kwargs) \u001b[38;5;129;01min\u001b[39;00m regressors\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 135\u001b[0m     y_pred, y_true \u001b[38;5;241m=\u001b[39m \u001b[43mrun_regression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs_still\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrun\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train_window\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m     predicted_angles \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtranspose(y_pred, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    137\u001b[0m     model_predictions[reg_name] \u001b[38;5;241m=\u001b[39m predicted_angles\n",
      "Cell \u001b[0;32mIn[3], line 66\u001b[0m, in \u001b[0;36mrun_regression\u001b[0;34m(epochs_train, cv_id, model_class, model_kwargs, t_train_window)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrunning cv #\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_chunk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m out of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(epochs_train\u001b[38;5;241m.\u001b[39mmetadata[cv_id]))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     60\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[1;32m     61\u001b[0m     epochs\u001b[38;5;241m=\u001b[39mepochs_train,\n\u001b[1;32m     62\u001b[0m     test_chunk\u001b[38;5;241m=\u001b[39mtest_chunk,\n\u001b[1;32m     63\u001b[0m     target_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdegrees\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     64\u001b[0m     cv_id\u001b[38;5;241m=\u001b[39mcv_id\n\u001b[1;32m     65\u001b[0m )\n\u001b[0;32m---> 66\u001b[0m y_predicted \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlinear_regression_timegen_window\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_train_window\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt_train_window\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m all_y_pred\u001b[38;5;241m.\u001b[39mappend(y_predicted)\n\u001b[1;32m     76\u001b[0m all_y_true\u001b[38;5;241m.\u001b[39mappend(y_test)\n",
      "File \u001b[0;32m~/anaconda3/envs/mne2/lib/python3.12/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mne2/lib/python3.12/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/mne2/lib/python3.12/site-packages/joblib/parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'Run some regression analyses within the still conditions'\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import mne\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from joblib import Parallel, delayed\n",
    "from collections import defaultdict\n",
    "from matplotlib.cm import get_cmap\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.stats import circstd\n",
    "\n",
    "def train_test_split(epochs, test_chunk, target_id, cv_id='session_nr'):\n",
    "    epochs_test = epochs[epochs.metadata[cv_id] == test_chunk]\n",
    "    epochs_train = epochs[epochs.metadata[cv_id] != test_chunk]\n",
    "    X_test = epochs_test._data\n",
    "    X_train = epochs_train._data\n",
    "\n",
    "    y_train = epochs_train.metadata[target_id].to_numpy()\n",
    "    y_test = epochs_test.metadata[target_id].to_numpy()\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def linear_regression_timegen_window(X_train, X_test, y_train_deg, model_class, model_kwargs, t_train_window, t_test):\n",
    "    y_train_sin = np.sin(np.deg2rad(y_train_deg))\n",
    "    y_train_cos = np.cos(np.deg2rad(y_train_deg))\n",
    "    X_train_avg = X_train[:, :, t_train_window[0]:t_train_window[1]].mean(axis=2)\n",
    "\n",
    "    pipe_sin = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('regression', model_class(**model_kwargs))\n",
    "    ])\n",
    "    pipe_cos = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('regression', model_class(**model_kwargs))\n",
    "    ])\n",
    "\n",
    "    pipe_sin.fit(X_train_avg, y_train_sin)\n",
    "    pipe_cos.fit(X_train_avg, y_train_cos)\n",
    "\n",
    "    y_pred_sin = pipe_sin.predict(X_test[:, :, t_test])\n",
    "    y_pred_cos = pipe_cos.predict(X_test[:, :, t_test])\n",
    "\n",
    "    y_pred_angle = np.rad2deg(np.arctan2(y_pred_sin, y_pred_cos)) % 360\n",
    "    return y_pred_angle\n",
    "\n",
    "def run_regression(epochs_train, cv_id, model_class, model_kwargs, t_train_window):\n",
    "    all_y_pred = []\n",
    "    all_y_true = []\n",
    "\n",
    "    for test_chunk in np.unique(epochs_train.metadata[cv_id]):\n",
    "        print(f'running cv #{test_chunk} out of {len(np.unique(epochs_train.metadata[cv_id]))}')\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            epochs=epochs_train,\n",
    "            test_chunk=test_chunk,\n",
    "            target_id='degrees',\n",
    "            cv_id=cv_id\n",
    "        )\n",
    "        y_predicted = Parallel(n_jobs=8)(\n",
    "            delayed(linear_regression_timegen_window)(\n",
    "                X_train, X_test, y_train,\n",
    "                model_class, model_kwargs,\n",
    "                t_train_window=t_train_window,\n",
    "                t_test=t\n",
    "            ) for t in range(X_test.shape[2])\n",
    "        )\n",
    "\n",
    "        all_y_pred.append(y_predicted)\n",
    "        all_y_true.append(y_test)\n",
    "\n",
    "    return np.array(all_y_pred), np.array(all_y_true)\n",
    "\n",
    "def get_train_window(peak_sample, window_size=30):\n",
    "    start = max(0, peak_sample - window_size)\n",
    "    end = peak_sample + window_size + 1\n",
    "    return (start, end)\n",
    "\n",
    "def circular_distance(pred, true):\n",
    "    return np.abs(((pred - true + 180) % 360) - 180)\n",
    "\n",
    "def signed_circular_distance(pred, true):\n",
    "    return ((pred - true + 180) % 360) - 180\n",
    "\n",
    "def resultant_vector_length(errors_deg):\n",
    "    radians = np.deg2rad(errors_deg)\n",
    "    return np.abs(np.mean(np.exp(1j * radians)))\n",
    "\n",
    "def compute_circular_error_metrics(errors_deg):\n",
    "    errors_rad = np.deg2rad(errors_deg)\n",
    "    circ_std = np.rad2deg(circstd(errors_rad, high=np.pi, low=-np.pi))\n",
    "    resultant_length = np.abs(np.mean(np.exp(1j * errors_rad)))\n",
    "    return circ_std, resultant_length\n",
    "\n",
    "subjects = [f\"S{i:02}\" for i in range(1, 16)]\n",
    "bids_dir = '/System/Volumes/Data/misc/data12/sjapee/Sebastian-OrientationImagery/Data/Bids/'\n",
    "data_path = f'{bids_dir}/derivatives/preprocessed/'\n",
    "\n",
    "regressors = {\n",
    "    'Ridge 1000': (Ridge, {'alpha': 1000})\n",
    "}\n",
    "\n",
    "csv_path = '/System/Volumes/Data/misc/data12/sjapee/Sebastian-OrientationImagery/!Important Data/LDA-16way Static/Mean/Peak_Times.csv'\n",
    "peak_df = pd.read_csv(csv_path, index_col='Subject')\n",
    "\n",
    "all_subject_errors = defaultdict(list)\n",
    "output_dir = \"/System/Volumes/Data/misc/data12/sjapee/Sebastian-OrientationImagery/!Important Data/WithinStillRegression\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "all_condition_errors = defaultdict(list)\n",
    "group_circ_stds = defaultdict(list)\n",
    "group_resultant_lengths = defaultdict(list)\n",
    "group_unsigned_errors = defaultdict(list)\n",
    "for Subject in subjects:\n",
    "    print(f\"Processing {Subject}\")\n",
    "    fn_still = f'sub-{Subject}_Still_preprocessed-epo.fif'\n",
    "    epochs_still = mne.read_epochs(data_path + fn_still)\n",
    "\n",
    "    epochs_still.metadata['degrees_string'] = [k.split('/')[-1] for k in epochs_still.metadata['trial_type']]\n",
    "    epochs_still = epochs_still[epochs_still.metadata['degrees_string'] != 'catch']\n",
    "    epochs_still.metadata['degrees'] = [int(i) for i in epochs_still.metadata['degrees_string']]\n",
    "    epochs_still.metadata.rename(columns={'run_nr': 'run'}, inplace=True)\n",
    "\n",
    "    peak1_sample = int(peak_df.loc['all', 'peak1_sample'])\n",
    "    t_train_window = get_train_window(peak1_sample, window_size=30)\n",
    "\n",
    "    model_predictions = {}\n",
    "    for reg_name, (model_class, model_kwargs) in regressors.items():\n",
    "        y_pred, y_true = run_regression(epochs_still, 'run', model_class, model_kwargs, t_train_window)\n",
    "        predicted_angles = np.transpose(y_pred, (0, 2, 1))\n",
    "        model_predictions[reg_name] = predicted_angles\n",
    "\n",
    "        np.save(os.path.join(output_dir, f\"{Subject}_{reg_name}_predictions.npy\"), predicted_angles)\n",
    "        np.save(os.path.join(output_dir, f\"{Subject}_{reg_name}_true.npy\"), y_true)\n",
    "\n",
    "    metadata = epochs_still.metadata\n",
    "    all_conditions = sorted(set(metadata['degrees_string']))\n",
    "    colors = get_cmap('viridis', len(all_conditions))\n",
    "\n",
    "    for reg_name, predicted_angles in model_predictions.items():\n",
    "        condition_signed_errors = {}\n",
    "        condition_unsigned_errors = {}\n",
    "        condition_metrics = {}\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        for condition in all_conditions:\n",
    "            condition_angle = int(condition)\n",
    "            condition_mask = metadata['degrees_string'].values == condition\n",
    "            condition_mask = condition_mask.reshape(4, 240)\n",
    "\n",
    "            pred = predicted_angles[condition_mask]\n",
    "            pred = pred.reshape(-1, predicted_angles.shape[2])\n",
    "\n",
    "            signed_errors = ((pred - condition_angle + 180) % 360) - 180\n",
    "            condition_signed_errors[condition_angle] = signed_errors\n",
    "\n",
    "            unsigned_errors = np.abs(signed_errors)\n",
    "            condition_unsigned_errors[condition_angle] = unsigned_errors\n",
    "            all_condition_errors[condition_angle].append(unsigned_errors)\n",
    "\n",
    "            circ_stds, result_lengths = zip(*[\n",
    "                compute_circular_error_metrics(signed_errors[:, t])\n",
    "                for t in range(signed_errors.shape[1])\n",
    "            ])\n",
    "\n",
    "            circ_stds = np.array(circ_stds)\n",
    "            result_lengths = np.array(result_lengths)\n",
    "            condition_metrics[condition_angle] = {\n",
    "                'circ_std': circ_stds,\n",
    "                'resultant_length': result_lengths\n",
    "            }\n",
    "            group_circ_stds[condition_angle].append(circ_stds)\n",
    "            group_resultant_lengths[condition_angle].append(result_lengths)\n",
    "            group_unsigned_errors[condition_angle].append(unsigned_errors)\n",
    "\n",
    "            plt.plot(gaussian_filter1d(circ_stds, 2), label=f'{condition_angle}°', linewidth=1, alpha=0.75)\n",
    "\n",
    "        mean_errors = np.array([condition_metrics[cond]['circ_std'] for cond in sorted(condition_metrics.keys())])\n",
    "        plt.plot(gaussian_filter1d(mean_errors.mean(axis=0), 2), label='Mean', color='black', linewidth=2, alpha = .85)\n",
    "\n",
    "        plt.title(f'{Subject} – Circular Std of Signed Error by Condition ({reg_name})')\n",
    "        plt.xlabel('Timepoints')\n",
    "        plt.ylabel('Circular Std (deg)')\n",
    "        plt.legend(ncol=4, fontsize=8)\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, f'{Subject}_{reg_name}_AllConditions_CircularStd.png'))\n",
    "        plt.close()\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        for condition_angle, metrics in condition_metrics.items():\n",
    "            plt.plot(gaussian_filter1d(metrics['resultant_length'], 2), label=f'{condition_angle}°', linewidth=1, alpha=0.75)\n",
    "        all_r = np.array([metrics['resultant_length'] for metrics in condition_metrics.values()])\n",
    "        plt.plot(gaussian_filter1d(all_r.mean(axis=0), 2), label='Mean', color='black', linewidth=2, alpha = .85)\n",
    "\n",
    "        plt.title(f'{Subject} – Resultant Vector Length by Condition ({reg_name})')\n",
    "        plt.xlabel('Timepoints')\n",
    "        plt.ylabel('Resultant Vector Length (R)')\n",
    "        plt.ylim(0, 1.05)\n",
    "        plt.legend(ncol=4, fontsize=8)\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, f'{Subject}_{reg_name}_AllConditions_ResultantLength.png'))\n",
    "        plt.close()\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        for condition_angle, errors in condition_unsigned_errors.items():\n",
    "            plt.plot(gaussian_filter1d(errors.mean(axis=0), 2), label=f'{condition_angle}°', linewidth=1, alpha=0.75)\n",
    "        all_mae = np.array([errors.mean(axis=0) for errors in condition_unsigned_errors.values()])\n",
    "        plt.plot(gaussian_filter1d(all_mae.mean(axis=0), 2), label='Mean', color='black', linewidth=2, alpha = .85)\n",
    "\n",
    "        plt.title(f'{Subject} – Unsigned Circular Error by Condition ({reg_name})')\n",
    "        plt.xlabel('Timepoints')\n",
    "        plt.ylabel('Mean Absolute Error (deg)')\n",
    "        plt.legend(ncol=4, fontsize=8)\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, f'{Subject}_{reg_name}_AllConditions_UnsignedError.png'))\n",
    "        plt.close()\n",
    "\n",
    "        np.save(os.path.join(output_dir, f\"{Subject}_{reg_name}_signed_errors.npy\"), condition_signed_errors)\n",
    "        np.save(os.path.join(output_dir, f\"{Subject}_{reg_name}_unsigned_errors.npy\"), condition_unsigned_errors)\n",
    "        np.save(os.path.join(output_dir, f\"{Subject}_{reg_name}_error_metrics.npy\"), condition_metrics)\n",
    "\n",
    "# === GROUP LEVEL AVERAGING AND PLOTTING ===\n",
    "print(\"Computing group-level averages...\")\n",
    "\n",
    "for metric_name, metric_dict in [\n",
    "    ('CircularStd', group_circ_stds),\n",
    "    ('ResultantLength', group_resultant_lengths),\n",
    "    ('UnsignedError', group_unsigned_errors)\n",
    "]:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for condition_angle in sorted(metric_dict.keys()):\n",
    "        all_data = np.array(metric_dict[condition_angle])\n",
    "        mean_metric = all_data.mean(axis=0)\n",
    "        smoothed = gaussian_filter1d(mean_metric, 2)\n",
    "        plt.plot(smoothed, label=f'{condition_angle}°', linewidth=1, alpha=0.75)\n",
    "\n",
    "    # Grand average across all conditions\n",
    "    all_means = [np.array(metric_dict[cond]) for cond in metric_dict]\n",
    "    stacked = np.vstack(all_means)\n",
    "    overall_mean = stacked.mean(axis=0)\n",
    "    smoothed_mean = gaussian_filter1d(overall_mean, 2)\n",
    "    plt.plot(smoothed_mean, label='Grand Mean', color='black', linewidth=2)\n",
    "\n",
    "    plt.title(f'Group-Level {metric_name} by Condition')\n",
    "    plt.xlabel('Timepoints')\n",
    "    ylabel = {\n",
    "        'CircularStd': 'Circular Std (deg)',\n",
    "        'ResultantLength': 'Resultant Vector Length (R)',\n",
    "        'UnsignedError': 'Mean Absolute Error (deg)'\n",
    "    }[metric_name]\n",
    "    plt.ylabel(ylabel)\n",
    "    if metric_name == 'ResultantLength':\n",
    "        plt.ylim(0, 1.05)\n",
    "    plt.grid(True)\n",
    "    plt.legend(ncol=4, fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, f'GroupAverage_{metric_name}_AllConditions.png'))\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "847cb45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing S01\n",
      "Reading /System/Volumes/Data/misc/data12/sjapee/Sebastian-OrientationImagery/Data/Bids/derivatives/preprocessed/sub-S01_Still_preprocessed-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     600.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Adding metadata with 8 columns\n",
      "1104 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "running cv #0 out of 4\n",
      "running cv #1 out of 4\n",
      "running cv #2 out of 4\n",
      "running cv #3 out of 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9m/6b08zp213znc3k12g6gpjj9rqx2ly9/T/ipykernel_94183/777387201.py:144: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  colors = get_cmap('viridis', len(all_conditions))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing S02\n",
      "Reading /System/Volumes/Data/misc/data12/sjapee/Sebastian-OrientationImagery/Data/Bids/derivatives/preprocessed/sub-S02_Still_preprocessed-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     600.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Adding metadata with 8 columns\n",
      "1104 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "running cv #0 out of 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process LokyProcess-95:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/montesinossl/anaconda3/envs/mne2/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/montesinossl/anaconda3/envs/mne2/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/montesinossl/anaconda3/envs/mne2/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py\", line 481, in _process_worker\n",
      "    if time() - _last_memory_leak_check > _MEMORY_LEAK_CHECK_DELAY:\n",
      "       ^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 135\u001b[0m\n\u001b[1;32m    133\u001b[0m model_predictions \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m reg_name, (model_class, model_kwargs) \u001b[38;5;129;01min\u001b[39;00m regressors\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 135\u001b[0m     y_pred, y_true \u001b[38;5;241m=\u001b[39m \u001b[43mrun_regression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs_still\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrun\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train_window\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m     predicted_angles \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtranspose(y_pred, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    137\u001b[0m     model_predictions[reg_name] \u001b[38;5;241m=\u001b[39m predicted_angles\n",
      "Cell \u001b[0;32mIn[17], line 66\u001b[0m, in \u001b[0;36mrun_regression\u001b[0;34m(epochs_train, cv_id, model_class, model_kwargs, t_train_window)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrunning cv #\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_chunk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m out of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(epochs_train\u001b[38;5;241m.\u001b[39mmetadata[cv_id]))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     60\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[1;32m     61\u001b[0m     epochs\u001b[38;5;241m=\u001b[39mepochs_train,\n\u001b[1;32m     62\u001b[0m     test_chunk\u001b[38;5;241m=\u001b[39mtest_chunk,\n\u001b[1;32m     63\u001b[0m     target_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdegrees\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     64\u001b[0m     cv_id\u001b[38;5;241m=\u001b[39mcv_id\n\u001b[1;32m     65\u001b[0m )\n\u001b[0;32m---> 66\u001b[0m y_predicted \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlinear_regression_timegen_window\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_train_window\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt_train_window\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m all_y_pred\u001b[38;5;241m.\u001b[39mappend(y_predicted)\n\u001b[1;32m     76\u001b[0m all_y_true\u001b[38;5;241m.\u001b[39mappend(y_test)\n",
      "File \u001b[0;32m~/anaconda3/envs/mne2/lib/python3.12/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mne2/lib/python3.12/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/mne2/lib/python3.12/site-packages/joblib/parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'producing std/vector length'\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import mne\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from joblib import Parallel, delayed\n",
    "from collections import defaultdict\n",
    "from matplotlib.cm import get_cmap\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.stats import circstd\n",
    "\n",
    "def train_test_split(epochs, test_chunk, target_id, cv_id='session_nr'):\n",
    "    epochs_test = epochs[epochs.metadata[cv_id] == test_chunk]\n",
    "    epochs_train = epochs[epochs.metadata[cv_id] != test_chunk]\n",
    "    X_test = epochs_test._data\n",
    "    X_train = epochs_train._data\n",
    "\n",
    "    y_train = epochs_train.metadata[target_id].to_numpy()\n",
    "    y_test = epochs_test.metadata[target_id].to_numpy()\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def linear_regression_timegen_window(X_train, X_test, y_train_deg, model_class, model_kwargs, t_train_window, t_test):\n",
    "    y_train_sin = np.sin(np.deg2rad(y_train_deg))\n",
    "    y_train_cos = np.cos(np.deg2rad(y_train_deg))\n",
    "    X_train_avg = X_train[:, :, t_train_window[0]:t_train_window[1]].mean(axis=2)\n",
    "\n",
    "    pipe_sin = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('regression', model_class(**model_kwargs))\n",
    "    ])\n",
    "    pipe_cos = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('regression', model_class(**model_kwargs))\n",
    "    ])\n",
    "\n",
    "    pipe_sin.fit(X_train_avg, y_train_sin)\n",
    "    pipe_cos.fit(X_train_avg, y_train_cos)\n",
    "\n",
    "    y_pred_sin = pipe_sin.predict(X_test[:, :, t_test])\n",
    "    y_pred_cos = pipe_cos.predict(X_test[:, :, t_test])\n",
    "\n",
    "    y_pred_angle = np.rad2deg(np.arctan2(y_pred_sin, y_pred_cos)) % 360\n",
    "    return y_pred_angle\n",
    "\n",
    "def run_regression(epochs_train, cv_id, model_class, model_kwargs, t_train_window):\n",
    "    all_y_pred = []\n",
    "    all_y_true = []\n",
    "\n",
    "    for test_chunk in np.unique(epochs_train.metadata[cv_id]):\n",
    "        print(f'running cv #{test_chunk} out of {len(np.unique(epochs_train.metadata[cv_id]))}')\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            epochs=epochs_train,\n",
    "            test_chunk=test_chunk,\n",
    "            target_id='degrees',\n",
    "            cv_id=cv_id\n",
    "        )\n",
    "        y_predicted = Parallel(n_jobs=8)(\n",
    "            delayed(linear_regression_timegen_window)(\n",
    "                X_train, X_test, y_train,\n",
    "                model_class, model_kwargs,\n",
    "                t_train_window=t_train_window,\n",
    "                t_test=t\n",
    "            ) for t in range(X_test.shape[2])\n",
    "        )\n",
    "\n",
    "        all_y_pred.append(y_predicted)\n",
    "        all_y_true.append(y_test)\n",
    "\n",
    "    return np.array(all_y_pred), np.array(all_y_true)\n",
    "\n",
    "def get_train_window(peak_sample, window_size=30):\n",
    "    start = max(0, peak_sample - window_size)\n",
    "    end = peak_sample + window_size + 1\n",
    "    return (start, end)\n",
    "\n",
    "def circular_distance(pred, true):\n",
    "    return np.abs(((pred - true + 180) % 360) - 180)\n",
    "\n",
    "def signed_circular_distance(pred, true):\n",
    "    return ((pred - true + 180) % 360) - 180\n",
    "\n",
    "def resultant_vector_length(errors_deg):\n",
    "    radians = np.deg2rad(errors_deg)\n",
    "    return np.abs(np.mean(np.exp(1j * radians)))\n",
    "\n",
    "def compute_circular_error_metrics(errors_deg):\n",
    "    errors_rad = np.deg2rad(errors_deg)\n",
    "    circ_std = np.rad2deg(circstd(errors_rad, high=np.pi, low=-np.pi))\n",
    "    resultant_length = np.abs(np.mean(np.exp(1j * errors_rad)))\n",
    "    return circ_std, resultant_length\n",
    "\n",
    "subjects = [f\"S{i:02}\" for i in range(1, 16)]\n",
    "bids_dir = '/System/Volumes/Data/misc/data12/sjapee/Sebastian-OrientationImagery/Data/Bids/'\n",
    "data_path = f'{bids_dir}/derivatives/preprocessed/'\n",
    "\n",
    "regressors = {\n",
    "    'Ridge 1000': (Ridge, {'alpha': 1000})\n",
    "}\n",
    "\n",
    "csv_path = \"/System/Volumes/Data/misc/data12/sjapee/Sebastian-OrientationImagery/Plots/BlenderExperiment/AllSubjects/WithinStill/ShrutiMay-22/SVM/AllSubjects_PeakTimes.csv\"\n",
    "peak_df = pd.read_csv(csv_path, index_col='Subject')\n",
    "\n",
    "all_subject_errors = defaultdict(list)\n",
    "output_dir = \"/System/Volumes/Data/misc/data12/sjapee/Sebastian-OrientationImagery/Plots/Jun2/Late\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "all_condition_errors = defaultdict(list)\n",
    "group_circ_stds = defaultdict(list)\n",
    "group_resultant_lengths = defaultdict(list)\n",
    "group_unsigned_errors = defaultdict(list)\n",
    "for Subject in subjects:\n",
    "    print(f\"Processing {Subject}\")\n",
    "    fn_still = f'sub-{Subject}_Still_preprocessed-epo.fif'\n",
    "    epochs_still = mne.read_epochs(data_path + fn_still)\n",
    "\n",
    "    epochs_still.metadata['degrees_string'] = [k.split('/')[-1] for k in epochs_still.metadata['trial_type']]\n",
    "    epochs_still = epochs_still[epochs_still.metadata['degrees_string'] != 'catch']\n",
    "    epochs_still.metadata['degrees'] = [int(i) for i in epochs_still.metadata['degrees_string']]\n",
    "    epochs_still.metadata.rename(columns={'run_nr': 'run'}, inplace=True)\n",
    "\n",
    "    peak1_sample = int(peak_df.loc[Subject, 'peak2_sample_plus240'])\n",
    "    t_train_window = get_train_window(peak1_sample, window_size=30)\n",
    "\n",
    "    model_predictions = {}\n",
    "    for reg_name, (model_class, model_kwargs) in regressors.items():\n",
    "        y_pred, y_true = run_regression(epochs_still, 'run', model_class, model_kwargs, t_train_window)\n",
    "        predicted_angles = np.transpose(y_pred, (0, 2, 1))\n",
    "        model_predictions[reg_name] = predicted_angles\n",
    "\n",
    "        np.save(os.path.join(output_dir + f\"/data/{Subject}_{reg_name}_predictions.npy\"), predicted_angles)\n",
    "        np.save(os.path.join(output_dir + f\"/data/{Subject}_{reg_name}_true.npy\"), y_true)\n",
    "\n",
    "    metadata = epochs_still.metadata\n",
    "    all_conditions = sorted(set(metadata['degrees_string']))\n",
    "    colors = get_cmap('viridis', len(all_conditions))\n",
    "\n",
    "    for reg_name, predicted_angles in model_predictions.items():\n",
    "        condition_signed_errors = {}\n",
    "        condition_unsigned_errors = {}\n",
    "        condition_metrics = {}\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        for condition in all_conditions:\n",
    "            condition_angle = int(condition)\n",
    "            condition_mask = metadata['degrees_string'].values == condition\n",
    "            condition_mask = condition_mask.reshape(4, 240)\n",
    "\n",
    "            pred = predicted_angles[condition_mask]\n",
    "            pred = pred.reshape(-1, predicted_angles.shape[2])\n",
    "\n",
    "            signed_errors = ((pred - condition_angle + 180) % 360) - 180\n",
    "            condition_signed_errors[condition_angle] = signed_errors\n",
    "\n",
    "            unsigned_errors = np.abs(signed_errors)\n",
    "            condition_unsigned_errors[condition_angle] = unsigned_errors\n",
    "            all_condition_errors[condition_angle].append(unsigned_errors)\n",
    "\n",
    "            circ_stds, result_lengths = zip(*[\n",
    "                compute_circular_error_metrics(signed_errors[:, t])\n",
    "                for t in range(signed_errors.shape[1])\n",
    "            ])\n",
    "\n",
    "            circ_stds = np.array(circ_stds)\n",
    "            result_lengths = np.array(result_lengths)\n",
    "            condition_metrics[condition_angle] = {\n",
    "                'circ_std': circ_stds,\n",
    "                'resultant_length': result_lengths\n",
    "            }\n",
    "            group_circ_stds[condition_angle].append(circ_stds)\n",
    "            group_resultant_lengths[condition_angle].append(result_lengths)\n",
    "            group_unsigned_errors[condition_angle].append(unsigned_errors)\n",
    "\n",
    "        # PLOT SIGNED ERROR WITH STANDARD DEVIATION\n",
    "        fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "        # Plot signed error on primary y-axis\n",
    "        for condition_angle, signed_errors in condition_signed_errors.items():\n",
    "            mean_signed = np.mean(signed_errors, axis=0)\n",
    "            std_signed = np.std(signed_errors, axis=0)\n",
    "\n",
    "            # Smooth both\n",
    "            mean_signed_smooth = gaussian_filter1d(mean_signed, 2)\n",
    "            std_signed_smooth = gaussian_filter1d(std_signed, 2)\n",
    "\n",
    "            ax1.plot(mean_signed_smooth, label=f'{condition_angle}°', linewidth=1.5, alpha=0.8)\n",
    "            ax1.fill_between(np.arange(len(mean_signed_smooth)),\n",
    "                            mean_signed_smooth - std_signed_smooth,\n",
    "                            mean_signed_smooth + std_signed_smooth,\n",
    "                            alpha=0.25)\n",
    "\n",
    "        # Mean across conditions\n",
    "        all_signed = np.array([signed for signed in condition_signed_errors.values()])\n",
    "        mean_across_conditions = np.mean(all_signed, axis=(0, 1))\n",
    "        std_across_conditions = np.std(all_signed, axis=(0, 1))\n",
    "\n",
    "        mean_across_conditions = gaussian_filter1d(mean_across_conditions, 2)\n",
    "        std_across_conditions = gaussian_filter1d(std_across_conditions, 2)\n",
    "        '''\n",
    "        ax1.plot(mean_across_conditions, label='Mean Across Conditions', color='black', linewidth=2)\n",
    "        ax1.fill_between(np.arange(len(mean_across_conditions)),\n",
    "                        mean_across_conditions - std_across_conditions,\n",
    "                        mean_across_conditions + std_across_conditions,\n",
    "                        color='gray', alpha=0.3)\n",
    "        '''\n",
    "        # Customize primary axis\n",
    "        ax1.set_xlabel('Timepoints')\n",
    "        ax1.set_ylabel('Signed Error (deg)', color='tab:blue')\n",
    "        ax1.axhline(0, color='k', linestyle='--', linewidth=1)\n",
    "        ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "        # Add second y-axis for normalized std\n",
    "        ax2 = ax1.twinx()\n",
    "        for condition_angle, signed_errors in condition_signed_errors.items():\n",
    "            std_signed = np.std(signed_errors, axis=0)\n",
    "            std_smooth = gaussian_filter1d(std_signed, 2)\n",
    "\n",
    "            # Normalize std for better visibility\n",
    "            std_norm = (std_smooth - np.min(std_smooth)) / (np.max(std_smooth) - np.min(std_smooth))\n",
    "\n",
    "            ax2.plot(std_norm, linestyle='--', alpha=0.3, label=f'{condition_angle}° Std')\n",
    "\n",
    "        ax2.set_ylabel('Normalized Std Dev (arbitrary units)', color='tab:red')\n",
    "        ax2.tick_params(axis='y', labelcolor='tab:red')\n",
    "\n",
    "        # Combined legend\n",
    "        lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "        lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "        fig.legend(lines1 + lines2, labels1 + labels2, loc='upper right', ncol=4, fontsize=8)\n",
    "\n",
    "        plt.title(f'{Subject} – Mean Signed Error with Variability ({reg_name})')\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, f'{Subject}_{reg_name}_SignedError_with_Variability.png'))\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        np.save(os.path.join(output_dir, f\"{Subject}_{reg_name}_signed_errors.npy\"), condition_signed_errors)\n",
    "        np.save(os.path.join(output_dir, f\"{Subject}_{reg_name}_error_metrics.npy\"), condition_metrics)\n",
    "\n",
    "# === GROUP LEVEL AVERAGING AND PLOTTING ===\n",
    "print(\"Computing group-level averages...\")\n",
    "\n",
    "# === GROUP-LEVEL PLOT: Signed error per condition averaged across subjects ===\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for condition_angle, subject_errors in all_condition_errors.items():\n",
    "    # subject_errors: list of arrays [n_trials x n_timepoints] per subject\n",
    "    all_errors = np.concatenate(subject_errors, axis=0)  # shape: (n_total_trials, n_timepoints)\n",
    "\n",
    "    # Compute mean and std across all trials (across all subjects)\n",
    "    mean_signed = np.mean(all_errors, axis=0)\n",
    "    std_signed = np.std(all_errors, axis=0)\n",
    "\n",
    "    # Smooth\n",
    "    mean_signed_smooth = gaussian_filter1d(mean_signed, 2)\n",
    "    std_signed_smooth = gaussian_filter1d(std_signed, 2)\n",
    "\n",
    "    plt.plot(mean_signed_smooth, label=f'{condition_angle}°', linewidth=1.5, alpha=0.8)\n",
    "    plt.fill_between(np.arange(len(mean_signed_smooth)),\n",
    "                     mean_signed_smooth - std_signed_smooth,\n",
    "                     mean_signed_smooth + std_signed_smooth,\n",
    "                     alpha=0.25)\n",
    "\n",
    "# Overall mean across all conditions\n",
    "all_errors_stack = np.concatenate([np.concatenate(errs, axis=0) for errs in all_condition_errors.values()], axis=0)\n",
    "mean_all = np.mean(all_errors_stack, axis=0)\n",
    "std_all = np.std(all_errors_stack, axis=0)\n",
    "\n",
    "mean_all_smooth = gaussian_filter1d(mean_all, 2)\n",
    "std_all_smooth = gaussian_filter1d(std_all, 2)\n",
    "\n",
    "plt.plot(mean_all_smooth, label='Mean Across Conditions', color='black', linewidth=2)\n",
    "plt.fill_between(np.arange(len(mean_all_smooth)),\n",
    "                 mean_all_smooth - std_all_smooth,\n",
    "                 mean_all_smooth + std_all_smooth,\n",
    "                 color='gray', alpha=0.3)\n",
    "\n",
    "plt.title('Group Average – Mean Signed Error by Condition')\n",
    "plt.xlabel('Timepoints')\n",
    "plt.ylabel('Signed Error (deg)')\n",
    "plt.axhline(0, color='k', linestyle='--', linewidth=1)\n",
    "plt.legend(ncol=4, fontsize=8)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, 'Group_Mean_SignedError_AllConditions.png'))\n",
    "plt.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
