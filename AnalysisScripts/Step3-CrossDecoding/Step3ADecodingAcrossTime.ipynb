{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de601d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Script to Cross-Decode Orientations in movies using LDA *by relative position in a movie over time*\"\"\"\n",
    "\n",
    "import os, mne, pickle, numpy as np, pandas as pd, time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import svm\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "#List of static conditions, adjust if you only want to look at the appearance of certain orientations (all are listed)\n",
    "input_numbers = [1, 22, 45, 67, 90, 112, 135, 157, 180, 202, 225, 247, 270, 292, 315, 337]\n",
    "\n",
    "\n",
    "def get_movie_orientation_sequence(movie_condition, input_numbers, n_steps=7):\n",
    "    \"\"\"\n",
    "    Given a movie condition (ie. '0022_Left') and a list of static orientations,\n",
    "    return the ordered list of what orientations the movie passes through.\n",
    "    movie_condition: string of a movie\n",
    "    input_numbers: orientations a movie can pass through\n",
    "    n_steps: how many orientations you want to see in order\n",
    "    \"\"\"\n",
    "    parts = movie_condition.split('_')\n",
    "    start_ori = int(parts[0])\n",
    "    direction = parts[1]  # 'Left' or 'Right'\n",
    "\n",
    "    if start_ori not in input_numbers:\n",
    "        raise ValueError(f\"Starting orientation {start_ori} not in input_numbers\")\n",
    "\n",
    "    start_idx = input_numbers.index(start_ori)\n",
    "    seq = []\n",
    "\n",
    "    for i in range(n_steps):\n",
    "        if direction == 'Right':\n",
    "            idx = (start_idx + i) % len(input_numbers)\n",
    "        elif direction == 'Left':\n",
    "            idx = (start_idx - i) % len(input_numbers)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown direction: {direction}\")\n",
    "        seq.append(f\"{input_numbers[idx]:04}\")  # pad to 4 digits\n",
    "\n",
    "    return seq\n",
    "\n",
    "def time_resolved_decoding_per_position(x_train, y_train, x_test, movie_condition, times, input_numbers, n_positions=7):\n",
    "    \"\"\"\n",
    "    Perform decoding for each timepoint, checking match with each position (1st, 2nd, ..., nth)\n",
    "    in the sequence of the movie.\n",
    "    Returns: array (n_positions, n_times) of proportion correct.\n",
    "    \"\"\"\n",
    "    orientation_sequence = get_movie_orientation_sequence(movie_condition, input_numbers, n_steps=n_positions)\n",
    "    n_times = x_test.shape[2]\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()), \n",
    "        ('classifier', LinearDiscriminantAnalysis(solver='eigen', shrinkage=0.01))\n",
    "    ])\n",
    "    pipe.fit(x_train, y_train)\n",
    "\n",
    "    accuracy_matrix = np.zeros((n_positions, n_times))  # shape: (position, time)\n",
    "\n",
    "    for t in range(n_times):\n",
    "        x_test_t = x_test[:, :, t]\n",
    "        preds = pipe.predict(x_test_t)  # shape: (n_trials,)\n",
    "        for pos in range(n_positions):\n",
    "            target_ori = orientation_sequence[pos]\n",
    "            acc = np.mean(preds == target_ori)\n",
    "            accuracy_matrix[pos, t] = acc\n",
    "\n",
    "    return accuracy_matrix, times\n",
    "\n",
    "def select_conditions(epochs_stacked,column_name,items_to_select):\n",
    "    \"\"\"\n",
    "    Select a specific set of conditions from an epochs object\n",
    "    \"\"\"\n",
    "    if type(items_to_select)==list:\n",
    "        selected_epochs = epochs_stacked[np.any([epochs_stacked.metadata[column_name] == i  for i in items_to_select],axis=0)]\n",
    "    if type(items_to_select)==str:\n",
    "        selected_epochs = epochs_stacked[epochs_stacked.metadata[column_name] == items_to_select]\n",
    "    return selected_epochs\n",
    "def train_test_split_cross(epo_stacked, epo_stackedMovie, test_condition, start_time, end_time):\n",
    "    \"\"\"\n",
    "    Creates a train-test split cross in which one averages across a training window and then goes across\n",
    "    all testing points\n",
    "    \"\"\"\n",
    "    # Test set: all timepoints\n",
    "    epochs_test = epo_stackedMovie[epo_stackedMovie.metadata['condition'] == test_condition]\n",
    "    y_test = epochs_test.metadata['condition'].to_numpy()\n",
    "    x_test = epochs_test._data  # shape: (n_trials, n_channels, n_times)\n",
    "\n",
    "    # Train set: Average across a given time-window\n",
    "    epochs_train = epo_stacked[epo_stacked.metadata['block_type'] == 'Still']\n",
    "    y_train = epochs_train.metadata['condition'].to_numpy()\n",
    "    mask = (epochs_train.times >= start_time) & (epochs_train.times <= end_time)\n",
    "    x_train = np.mean(epochs_train._data[:, :, mask], axis=2)  # mean over time\n",
    "\n",
    "    return x_train, x_test, y_train, y_test, epochs_test.times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcf4d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subjects_results = []\n",
    "all_static_accuracies = []\n",
    "subjects = [f\"S{i:02}\" for i in range(1, 21)]\n",
    "data_path = '/System/Volumes/Data/misc/data12/sjapee/Sebastian-OrientationImagery/Data/Bids/derivatives/preprocessed/'\n",
    "csv_path = '/System/Volumes/Data/misc/data12/sjapee/Sebastian-OrientationImagery/!Important Data/LDA-16way Static/Peak_Times.csv'\n",
    "output_dir = '/System/Volumes/Data/misc/data12/sjapee/Sebastian-OrientationImagery/!Important Data/ProportionsOverTime'\n",
    "peak_df = pd.read_csv(csv_path, index_col='Subject')\n",
    "#Loop to produce plots\n",
    "for subject in subjects:\n",
    "    print(f\"Processing {subject}...\")\n",
    "    # Load epochs\n",
    "    fn_still = f'sub-{subject}_Still_preprocessed-epo.fif'\n",
    "    fn_dynamic = f'sub-{subject}_Dynamic_preprocessed-epo.fif'\n",
    "    epochs_still = mne.read_epochs(data_path + fn_still, preload=True)\n",
    "    epochs_dynamic = mne.read_epochs(data_path + fn_dynamic, preload=True)\n",
    "\n",
    "    # Select only relevant conditions (exclude catch trials)\n",
    "    epochs_selected = select_conditions(epochs_still, column_name='condition', items_to_select=[\n",
    "        '0001', '0022', '0045', '0067', '0090', '0112', '0135', '0157',\n",
    "        '0180', '0202', '0225', '0247', '0270', '0292', '0315', '0337'])\n",
    "    epochs_selectedMovie = select_conditions(epochs_dynamic, column_name='condition', items_to_select=[\n",
    "        '0022_Left', '0022_Right', '0067_Left', '0067_Right', '0112_Left', '0112_Right',\n",
    "        '0157_Left', '0157_Right', '0202_Left', '0202_Right', '0247_Left', '0247_Right',\n",
    "        '0292_Left', '0292_Right', '0337_Left', '0337_Right'])\n",
    "\n",
    "    #Find the peak time window for within-still decoding for a given subject to use for our training window for cross-decoding\n",
    "    #Choose peak1 for early peaks and peak2 for later peaks\n",
    "    peak_sample = int(peak_df.loc['all', 'peak2_sample'])\n",
    "    start_time = epochs_selected.times[peak_sample - 18]\n",
    "    end_time = epochs_selected.times[peak_sample + 18]\n",
    "\n",
    "\n",
    "    n_positions = 9\n",
    "    times = epochs_selectedMovie.times\n",
    "    subject_acc_matrix = np.zeros((n_positions, len(times)))  # average across movies\n",
    "\n",
    "    movie_conditions = epochs_selectedMovie.metadata['condition'].unique()\n",
    "    for cond in movie_conditions:\n",
    "        x_train, x_test, y_train, y_test, times = train_test_split_cross(\n",
    "            epochs_selected, epochs_selectedMovie, cond, start_time, end_time)\n",
    "\n",
    "        acc_matrix, times = time_resolved_decoding_per_position(\n",
    "            x_train, y_train, x_test, cond, times, input_numbers, n_positions=n_positions)\n",
    "\n",
    "        subject_acc_matrix += acc_matrix\n",
    "\n",
    "    subject_acc_matrix /= len(movie_conditions)  # mean across movies\n",
    "    np.save(f\"{output_dir}/{subject}_SequencedAccuracyLateall.npy\", subject_acc_matrix)\n",
    "    all_subjects_results.append(subject_acc_matrix)  # shape: (n_subjects, n_positions, n_times)\n",
    "#Train test split for cross decoding\n",
    "all_subjects_results = np.array(all_subjects_results)  # shape: (n_subjects, n_positions, n_times)\n",
    "group_avg = np.mean(all_subjects_results, axis=0)  # shape: (n_positions, n_times)\n",
    "np.save(f\"{output_dir}/GroupAverage_SequencedAccuracyLateall.npy\", group_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6101dde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Plotting code, go to plotting script to load in and plot if you don't want to plot here\"\"\"\n",
    "plt.figure(figsize=(15, 6))\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, n_positions))\n",
    "\n",
    "for pos in range(n_positions):\n",
    "    smoothed = gaussian_filter1d(group_avg[pos], sigma=2)\n",
    "    plt.plot(times, smoothed, label=f'{pos+1}Â° in sequence', color=colors[pos])\n",
    "    onset_time = pos * 0.375\n",
    "    if times[0] <= onset_time <= times[-1]:\n",
    "        plt.axvline(onset_time, linestyle='--', color=colors[pos], alpha=0.8, linewidth=1.2)\n",
    "\n",
    "plt.axhline(1/16, linestyle='--', color='gray', label='Chance')\n",
    "plt.axvline(0, linestyle='--', color='black', label='Movie Onset')\n",
    "\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Proportion Correct')\n",
    "plt.title('Cross-Decoding Accuracy by Sequence Position')\n",
    "\n",
    "# ğŸ§± Move legend outside\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1.0, 1.0))\n",
    "\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1])  # leave space on the right\n",
    "plt.plot()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
