{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##SCRIPT TO CHECK THE DURATION/TIMING OF TRIALS IN MEG USING THE PHOTODIODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import pylab\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from hv_proc.utilities import mrk_template_writer\n",
    "\n",
    "S = 'test360'\n",
    "proj_path = \"/misc/data12/sjapee/Sebastian-OrientationImagery/Data/\"\n",
    "raw_dir = proj_path + '20240629/' + S + '/'\n",
    "logfile_dir = proj_path + 'sheets/'\n",
    "run_Length = 1\n",
    "stim_duration = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New way of defining onsets not based on standard deviation but based on finding photodiode after the trigger\n",
    "def defineOnsets2(raw, events):\n",
    "    log_statements = []\n",
    "    pd_dat = raw[raw.ch_names.index('UADC016-2104')][0][0]\n",
    "    if np.mean(np.abs(pd_dat))>0.6: # this should be fine but may not be good if there are a looot of zeros\n",
    "        # zero-centering & making everything positive\n",
    "        pd_dat = np.abs(pd_dat-np.mean(pd_dat[0:100]))\n",
    "        # scaling channel to 0-1\n",
    "        pd_dat = (pd_dat-np.min(pd_dat)) / (np.max(pd_dat)-np.min(pd_dat))\n",
    "\n",
    "        # using the event, we are now looking in the next 50ms of the photodiode channel (digital) when the signal goes above 0.5\n",
    "        t_samples = int(0.05/(1/raw.info['sfreq']))\n",
    "        threshold =  .5\n",
    "\n",
    "        # when we found the events we calculate the trigger delay. \n",
    "        pd_events = [events[i,0]+np.where(pd_dat[events[i,0]:events[i,0]+t_samples]<threshold)[0][0] for i in range(len(events))]\n",
    "        pd_onsets = []\n",
    "        pd_offsets = []\n",
    "\n",
    "        for event in events:\n",
    "            # Find onset\n",
    "            onset_index = event[0] + np.argmax(pd_dat[event[0]:event[0] + t_samples] > threshold)\n",
    "            pd_onsets.append(onset_index)\n",
    "\n",
    "            # Find offset\n",
    "            pd_offset_index = onset_index + np.argmax(pd_dat[onset_index:] < threshold)\n",
    "            pd_offsets.append(pd_offset_index)\n",
    "        trigger_delay = 1000. * (pd_events-events[:, 0]) / raw.info['sfreq']\n",
    "        # sometimes this channel records ON as UP and sometimes as DOWN. This if-loop makes sure we always find the onsets\n",
    "        if np.mean(trigger_delay)==0:\n",
    "            pd_events = [events[i,0]+np.where(pd_dat[events[i,0]:events[i,0]+t_samples]>threshold)[0][0] for i in range(len(events))]\n",
    "            trigger_delay = 1000. * (pd_events-events[:, 0]) / raw.info['sfreq']\n",
    "        log_statements.append(('Trigger delay removed (μ ± σ): %0.1f ± %0.1f ms')\n",
    "            % (np.mean(trigger_delay), np.std(trigger_delay)))\n",
    "        if np.mean(trigger_delay)>10:\n",
    "            events[:,0] = events[:,0]+5\n",
    "            log_statements.append(f'photo diode and parallel port triggers are too far apart. using parallel port trigger ')\n",
    "        else:\n",
    "            log_statements.append(f'photo diode used successfully ')\n",
    "            events[:, 0] = pd_events\n",
    "    else: \n",
    "        # if the pd channel didn't work, add 5 samples as a standard delay\n",
    "        events[:,0] = events[:,0]+5\n",
    "        log_statements.append(f'photo diode did not record anything. using parallel port trigger ')\n",
    "\n",
    "    return raw,events,log_statements, pd_onsets, pd_offsets\n",
    "def prepMarkers():\n",
    "    subs   = ['S01']\n",
    "    block_conditions = {\n",
    "        'Watch_Still': ['0022_Left', '0022_Right', '0067_Left', '0067_Right', '0122_Left', '0122_Right', \n",
    "                        '0157_Left', '0157_Right', '0202_Left', '0202_Right', '0247_Left', '0247_Right',\n",
    "                        '0292_Left', '0292_Right', '0337_Left', '0337_Right']}\n",
    "    trial_data = []\n",
    "    blocks = list(block_conditions.keys())\n",
    "    for block in blocks:\n",
    "        conditions = block_conditions[block]\n",
    "        for condition in conditions:\n",
    "            block_data = {'Block': block, 'Condition': condition}\n",
    "            trial_data.append(block_data)\n",
    "\n",
    "    df = pd.DataFrame(trial_data)\n",
    "    print(df)\n",
    "    df['Code'] = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
    "    ids = df['Code']\n",
    "    conds = df['Block']\n",
    "    orients = df['Condition']\n",
    "    event_id = {}\n",
    "    for i, id in enumerate(ids):\n",
    "        event_id[id] = f'{subs[0]}/{conds[i]}/{orients[i]}'\n",
    "    #keys = [f'{sub}/{cond}/{orient}/{id}' for sub in subs for id in ids for cond in conds for orient in orients]\n",
    "    return event_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "['/misc/data12/sjapee/Sebastian-OrientationImagery/Data/20240629/test360/MEG_OrientationImagery_20240629_001.ds']\n",
      "          Block   Condition\n",
      "0   Watch_Still   0022_Left\n",
      "1   Watch_Still  0022_Right\n",
      "2   Watch_Still   0067_Left\n",
      "3   Watch_Still  0067_Right\n",
      "4   Watch_Still   0122_Left\n",
      "5   Watch_Still  0122_Right\n",
      "6   Watch_Still   0157_Left\n",
      "7   Watch_Still  0157_Right\n",
      "8   Watch_Still   0202_Left\n",
      "9   Watch_Still  0202_Right\n",
      "10  Watch_Still   0247_Left\n",
      "11  Watch_Still  0247_Right\n",
      "12  Watch_Still   0292_Left\n",
      "13  Watch_Still  0292_Right\n",
      "14  Watch_Still   0337_Left\n",
      "15  Watch_Still  0337_Right\n"
     ]
    }
   ],
   "source": [
    "#*****************************#\n",
    "### PARAMETERS ###\n",
    "#*****************************#\n",
    "\n",
    "l_freq                      = 0.1\n",
    "h_freq                      = 100\n",
    "notch                       = 60\n",
    "notch_max                   = 240\n",
    "pre_stim_time               = -.2\n",
    "post_stim_time              = 3.2\n",
    "std_deviations_above_below  = 4\n",
    "output_resolution           = 200\n",
    "trigger_channel             = 'UPPT001'\n",
    "\n",
    "\n",
    "dsets = []\n",
    "for i in range(1,2):\n",
    "    print(i)\n",
    "    ds = f'00{i}'\n",
    "    dsets.append(raw_dir + glob.glob('*_' + ds +'.ds',root_dir=raw_dir)[0]) \n",
    "#dsets.append(raw_dir + glob.glob('*_' + '006' +'.ds',root_dir=raw_dir)[0]) \n",
    "print(dsets)\n",
    "\n",
    "\n",
    "event_ids = prepMarkers()\n",
    "event_id = {v:k for k,v in event_ids.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ds directory : /misc/data12/sjapee/Sebastian-OrientationImagery/Data/20240629/test360/MEG_OrientationImagery_20240629_001.ds\n",
      "    res4 data read.\n",
      "    hc data read.\n",
      "    Separate EEG position data file not present.\n",
      "    Quaternion matching (desired vs. transformed):\n",
      "       0.00   80.00    0.00 mm <->    0.00   80.00    0.00 mm (orig :  -56.57   56.57 -210.00 mm) diff =    0.000 mm\n",
      "       0.00  -80.00    0.00 mm <->    0.00  -80.00    0.00 mm (orig :   56.57  -56.57 -210.00 mm) diff =    0.000 mm\n",
      "      80.00    0.00    0.00 mm <->   80.00   -0.00    0.00 mm (orig :   56.57   56.57 -210.00 mm) diff =    0.000 mm\n",
      "    Coordinate transformations established.\n",
      "    Polhemus data for 3 HPI coils added\n",
      "    Device coordinate locations for 3 HPI coils added\n",
      "    Measurement info composed.\n",
      "Finding samples for /misc/data12/sjapee/Sebastian-OrientationImagery/Data/20240629/test360/MEG_OrientationImagery_20240629_001.ds/MEG_OrientationImagery_20240629_001.meg4: \n",
      "    System clock channel is available, but ignored.\n",
      "    1 x 1200000 = 1200000 samples from 311 chs\n",
      "Current compensation grade : 3\n",
      "Reading 0 ... 1199999  =      0.000 ...   999.999 secs...\n",
      "Trigger channel UPPT001 has a non-zero initial value of {initial_value} (consider using initial_event=True to detect this event)\n",
      "Removing orphaned offset at the beginning of the file.\n",
      "129 events found on stim channel UPPT001\n",
      "Event IDs: [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17 255]\n"
     ]
    }
   ],
   "source": [
    "pd_time = []\n",
    "\n",
    "for i in range(len(dsets)):\n",
    "    raw = mne.io.read_raw_ctf(dsets[i],system_clock='ignore',preload=True)\n",
    "    events = mne.find_events(raw, stim_channel='UPPT001',min_duration = 0.002)\n",
    "    raw, events, log_statements, pd_onsets, pd_offsets = defineOnsets2(raw, events)\n",
    "    pd_onsets_np = np.array(pd_onsets)\n",
    "    pd_offsets_np = np.array(pd_offsets)\n",
    "    offsets_minus_onsets_np = pd_offsets_np - pd_onsets_np\n",
    "    pd_time.extend(offsets_minus_onsets_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value: 139, Count: 3, Indices: [0 1 2]\n",
      "Value: 3718, Count: 52, Indices: [  3   6   7   9  13  16  19  20  23  26  29  30  32  33  36  39  42  43\n",
      "  46  49  55  56  59  62  63  65  66  69  72  75  76  78  79  82  85  86\n",
      "  92  95  96  98  99 102 103 107 108 110 111 114 118 122 125 128]\n",
      "Value: 3719, Count: 58, Indices: [  4   5   8  11  12  14  15  18  22  25  27  28  34  35  37  40  41  44\n",
      "  47  48  50  51  53  54  57  58  60  61  64  68  70  71  73  77  80  81\n",
      "  83  84  87  88  90  91  93  94 100 101 106 109 112 115 116 117 119 120\n",
      " 123 124 126 127]\n",
      "Value: 3738, Count: 1, Indices: [104]\n",
      "Value: 3739, Count: 1, Indices: [21]\n",
      "Value: 4518, Count: 3, Indices: [ 52  89 121]\n",
      "Value: 4519, Count: 10, Indices: [ 17  24  31  38  45  67  74  97 105 113]\n",
      "Value: 4598, Count: 1, Indices: [10]\n"
     ]
    }
   ],
   "source": [
    "# Get unique values and their counts\n",
    "unique_values, counts = np.unique(pd_time, return_counts=True)\n",
    "\n",
    "# Find indices for each unique value\n",
    "indices = [np.where(pd_time == value)[0] for value in unique_values]\n",
    "\n",
    "# Print unique values, counts, and indices\n",
    "for value, count, idx in zip(unique_values, counts, indices):\n",
    "    print(f\"Value: {value}, Count: {count}, Indices: {idx}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
